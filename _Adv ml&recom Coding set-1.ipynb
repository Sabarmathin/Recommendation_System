{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f45b108c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features:\n",
      " ['Salary']\n"
     ]
    }
   ],
   "source": [
    "#1.\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, chi2,mutual_info_classif\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Age': [25, 32, 47, 51, 62],\n",
    "    'Salary': [40000, 50000, 60000, 52000, 62000],\n",
    "    'Purchased': [0, 1, 1, 0, 1]\n",
    "})\n",
    "\n",
    "X = df[['Age', 'Salary']]\n",
    "y = df['Purchased']\n",
    "#Use Mutual Information to find the most important feature for predicting Purchased. Select the top 1 feature.\n",
    "selector = SelectKBest(score_func=mutual_info_classif, k=1)\n",
    "X_new = selector.fit_transform(X, y)\n",
    "print(\"Selected features:\\n\", X.columns[selector.get_support()].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72f065fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Apple', 'Banana']\n"
     ]
    }
   ],
   "source": [
    "#2.\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'User': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
    "    'Item': ['Apple', 'Banana', 'Apple', 'Orange', 'Banana', 'Orange'],\n",
    "    'Rating': [5, 3, 4, 2, 5, 4]\n",
    "})\n",
    "\n",
    "popular_item = data.groupby('Item')['Rating'].sum().sort_values(ascending = False).head(2)\n",
    "print(popular_item.index.to_list())\n",
    "\n",
    "# Based on item popularity (sum of ratings), recommend top 2 items to a new user.\n",
    "\n",
    "#  Expected Output:\n",
    "\n",
    "# ['Apple', 'Banana']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43499af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: ['bmi', 'bp', 's1', 's2', 's5']\n"
     ]
    }
   ],
   "source": [
    "#3.\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "import pandas as pd\n",
    "\n",
    "X, y = load_diabetes(return_X_y=True, as_frame=True)\n",
    "\n",
    "\n",
    "log_rfe = RFE(estimator=LinearRegression(), n_features_to_select=5)\n",
    "log_fit = log_rfe.fit(X, y)\n",
    "log_rfe_feature=log_fit.transform(X)\n",
    "print(\"Selected features:\",X.columns[log_fit.get_support()].to_list())\n",
    "\n",
    "# Write a Python program to perform feature selection using Recursive Feature Elimination (RFE). Use Linear Regression as the estimator and select the top 5 features. Print the selected feature names.\n",
    "\n",
    "# Expected output:\n",
    "# Selected features: ['bmi', 's5', 'bp', 'age', 'sex']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4537a4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 8 features using mutual info: ['pixel_2_5', 'pixel_3_2', 'pixel_3_6', 'pixel_4_1', 'pixel_4_2', 'pixel_5_2', 'pixel_5_3', 'pixel_7_5']\n"
     ]
    }
   ],
   "source": [
    "#4.\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.feature_selection import SelectKBest,mutual_info_classif\n",
    "import pandas as pd\n",
    "\n",
    "X, y = load_digits(return_X_y=True, as_frame=True)\n",
    "\n",
    "selectkbest_alog = SelectKBest(score_func=mutual_info_classif, k=8)\n",
    "selectkbest_fit = selectkbest_alog.fit(X, y)\n",
    "\n",
    "print(\"Top 8 features using mutual info:\",X.columns[selectkbest_fit.get_support()].to_list())\n",
    "\n",
    "# Write a Python program that selects the top 8 features using SelectKBest with mutual_info_classif as the scoring function. Print the names of the selected features.\n",
    "\n",
    "# ðŸŽ¯ Expected Output:\n",
    "#     Top 8 features using mutual info: ['pixel_0_1', 'pixel_0_6', 'pixel_1_5', 'pixel_2_2', 'pixel_2_5', 'pixel_4_2', 'pixel_5_1', 'pixel_7_4']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff2f6934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: ['mean radius', 'mean texture', 'mean perimeter', 'texture error', 'worst radius', 'worst texture', 'worst perimeter', 'worst compactness', 'worst concavity']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SAIRAM\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#5.\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import pandas as pd\n",
    "\n",
    "X, y = load_breast_cancer(return_X_y=True, as_frame=True)\n",
    "\n",
    "selector = SelectFromModel(LogisticRegression(), threshold=\"mean\",max_features = 9)\n",
    "selector_fit = selector.fit(X, y)\n",
    "\n",
    "print(\"Selected features:\",X.columns[selector_fit.get_support()].to_list())\n",
    "# Write a Python program to perform feature selection using SelectFromModel. Train a Logistic Regression model and select features based on importance using SelectFromModel. Print the names of the selected feature\n",
    "\n",
    "\n",
    "# Expected Output:\n",
    "# Selected features: ['mean radius', 'mean concavity', 'texture error', 'worst texture', 'worst smoothness', 'worst compactness', 'worst concavity', 'worst concave points', 'worst symmetry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4302975",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36051c7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecba703b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
